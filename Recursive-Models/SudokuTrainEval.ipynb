{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMYPunymG8XUZHPXslZ9Je"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5lO29OeBeoLa"},"outputs":[],"source":["def sample_to_grid(tensor, process=\"tokenized\"):\n","    \"\"\"\n","    Convert a processed sudoku tensor back to 9x9 grid format for display\n","\n","    Args:\n","        tensor: Processed sudoku tensor\n","        process: Processing method used (\"one-hot\", \"tokenized\", or \"number\")\n","\n","    Returns:\n","        String representation of the sudoku grid\n","    \"\"\"\n","    # Convert tensor to list of numbers (1-9, 0 for empty)\n","    if process == \"number\":\n","        # Already in number format, just convert 0 to '.'\n","        numbers = tensor.cpu().numpy().astype(int)\n","    elif process == \"one-hot\":\n","        # Reshape from 729 to (81, 9) and get argmax\n","        reshaped = tensor.reshape(81, 9)\n","        numbers = []\n","        for cell in reshaped:\n","            if cell.sum() == 0:\n","                numbers.append(0)\n","            else:\n","                numbers.append(cell.argmax().item() + 1)\n","    elif process == \"tokenized\":\n","        # Shape is (81, 9), get argmax for each cell\n","        numbers = []\n","        for cell in tensor:\n","            if cell.sum() == 0:\n","                numbers.append(0)\n","            else:\n","                numbers.append(cell.argmax().item() + 1)\n","    else:\n","        raise ValueError(f\"Unknown process type: {process}\")\n","\n","    # Build the grid string\n","    grid_str = \"\"\n","    for i in range(9):\n","        if i % 3 == 0 and i != 0:\n","            grid_str += \"------+-------+------\\n\"\n","\n","        for j in range(9):\n","            if j % 3 == 0 and j != 0:\n","                grid_str += \"| \"\n","\n","            idx = i * 9 + j\n","            if numbers[idx] == 0:\n","                grid_str += \". \"\n","            else:\n","                grid_str += f\"{numbers[idx]} \"\n","\n","        grid_str += \"\\n\"\n","\n","    return grid_str\n","\n","def create_model():\n","    \"\"\"Create model based on selected configuration\"\"\"\n","    if model_type == \"StaticDEQ\":\n","        model = StaticDEQ(\n","            T=T, C=C, D=static_hidden_dimension,\n","            L=static_iterations, N=static_num_weight_matrices,\n","            hid_activation=hidden_activation,\n","            output_activation=output_activation,\n","            weight_init=weight_initialization,\n","            bias=use_bias\n","        )\n","    elif model_type == \"HierarchicalDEQ\":\n","        Ls = [int(x.strip()) for x in hier_iterations_per_stage.split(',')]\n","        Ns = [int(x.strip()) for x in hier_weight_matrices_per_stage.split(',')]\n","        s_dims = [int(x.strip()) for x in hier_stage_dimensions.split(',')]\n","        model = HierarchicalDEQ(\n","            C=C, D=hier_hidden_dimension, Ls=Ls, Ns=Ns, s_dims=s_dims,\n","            hid_activation=hidden_activation,\n","            output_activation=output_activation,\n","            weight_init=weight_initialization,\n","            bias=use_bias,\n","            weight_share=hier_weight_share\n","        )\n","    elif model_type == \"HyperDEQ\":\n","        model = HyperDEQ(\n","            T=T, C=C, D=hyper_hidden_dimension,\n","            L=hyper_iterations, N=hyper_num_weight_generation_steps,\n","            H=hyper_num_heads, E=hyper_head_dimension,\n","            hid_activation=hidden_activation,\n","            output_activation=output_activation,\n","            weight_init=weight_initialization,\n","            bias=use_bias,\n","            weight_share=hyper_weight_share\n","        )\n","    else:\n","        raise ValueError(f\"Unknown model type: {model_type}\")\n","\n","    if use_sudoku_positional:\n","        model = add_sudoku_positional_encoding(model)\n","\n","    return model.to(device)\n","\n","def create_optimizer(model):\n","    \"\"\"Create optimizer based on configuration\"\"\"\n","    if optimizer_type == \"Adam\":\n","        return optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    elif optimizer_type == \"AdamW\":\n","        return optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    elif optimizer_type == \"SGD\":\n","        return optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum_for_sgd)\n","    elif optimizer_type == \"RMSprop\":\n","        return optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    else:\n","        raise ValueError(f\"Unknown optimizer type: {optimizer_type}\")\n","\n","def digit_entropy_loss(output):\n","    \"\"\"\n","    数独の各セクション（行、列、3x3ブロック）で数字の分布エントロピーを最大化\n","\n","    Args:\n","        output: (B, 81, 9) - モデルの出力（logitsまたはsoftmax後）\n","\n","    Returns:\n","        エントロピー損失（スカラー、正の値）\n","    \"\"\"\n","    B = output.shape[0]\n","\n","    # Softmaxで確率化（既にsoftmax済みなら不要だが、安全のため）\n","    probs = F.softmax(output, dim=-1)\n","    probs_2d = probs.view(B, 9, 9, 9)  # (B, row, col, digit)\n","\n","    eps = 1e-8\n","    total_entropy = 0\n","    count = 0\n","\n","    # 行のエントロピー\n","    for row in range(9):\n","        row_probs = probs_2d[:, row, :, :]  # (B, 9, 9)\n","        # 各数字の平均確率\n","        digit_dist = row_probs.mean(dim=1)  # (B, 9)\n","        # エントロピー計算\n","        entropy = -(digit_dist * torch.log(digit_dist + eps)).sum(dim=-1)\n","        total_entropy += entropy.mean()\n","        count += 1\n","\n","    # 列のエントロピー\n","    for col in range(9):\n","        col_probs = probs_2d[:, :, col, :]  # (B, 9, 9)\n","        digit_dist = col_probs.mean(dim=1)  # (B, 9)\n","        entropy = -(digit_dist * torch.log(digit_dist + eps)).sum(dim=-1)\n","        total_entropy += entropy.mean()\n","        count += 1\n","\n","    # 3x3ブロックのエントロピー\n","    for br in range(3):\n","        for bc in range(3):\n","            block = probs_2d[:, br*3:(br+1)*3, bc*3:(bc+1)*3, :]\n","            block_flat = block.reshape(B, 9, 9)  # (B, cells_in_block, digits)\n","            digit_dist = block_flat.mean(dim=1)  # (B, 9)\n","            entropy = -(digit_dist * torch.log(digit_dist + eps)).sum(dim=-1)\n","            total_entropy += entropy.mean()\n","            count += 1\n","\n","    # 平均エントロピー（27セクション分）\n","    avg_entropy = total_entropy / count\n","\n","    # 最大エントロピー（log(9)）で正規化\n","    max_entropy = torch.log(torch.tensor(9.0))\n","    normalized_entropy = avg_entropy / max_entropy\n","\n","    # 損失として返す（エントロピーが高いほど良いので負にする）\n","    return -normalized_entropy\n","\n","def compute_loss(output, target, input_mask=None, entropy_weight=0.0):\n","    \"\"\"Compute cross-entropy loss with optional entropy regularization\"\"\"\n","    # output: (B, T, C), target: (B, T, C)\n","    B, T_dim, C_dim = output.shape\n","\n","    # Convert one-hot target to class indices\n","    target_indices = target.argmax(dim=-1)  # (B, T)\n","\n","    # Reshape for cross-entropy\n","    output_flat = output.view(B * T_dim, C_dim)\n","    target_flat = target_indices.view(B * T_dim)\n","\n","    if loss_on_empty_cells_only and input_mask is not None:\n","        # Only compute loss on empty cells\n","        mask_flat = input_mask.view(B * T_dim)\n","        ce_loss = nn.CrossEntropyLoss(reduction='none')(output_flat, target_flat)\n","        ce_loss = (ce_loss * mask_flat).sum() / mask_flat.sum()\n","    else:\n","        ce_loss = nn.CrossEntropyLoss()(output_flat, target_flat)\n","\n","    # エントロピー正則化を追加\n","    if entropy_weight > 0:\n","        entropy_loss = digit_entropy_loss(output)\n","        total_loss = ce_loss + entropy_weight * entropy_loss\n","    else:\n","        total_loss = ce_loss\n","\n","    return total_loss\n","\n","def evaluate_accuracy(output, target, input_data):\n","    \"\"\"Calculate various accuracy metrics\"\"\"\n","    B, T_dim, C_dim = output.shape\n","\n","    # Get predictions\n","    pred_indices = output.argmax(dim=-1)  # (B, T)\n","    target_indices = target.argmax(dim=-1)  # (B, T)\n","\n","    # Identify empty cells in input\n","    input_empty = (input_data.sum(dim=-1) == 0)  # (B, T)\n","\n","    # Complete accuracy: completely solved puzzles\n","    complete_correct = (pred_indices == target_indices).all(dim=1).float().mean().item()\n","\n","    # Empty cell accuracy: accuracy on originally empty cells\n","    if input_empty.sum() > 0:\n","        empty_correct = ((pred_indices == target_indices) * input_empty).sum().item()\n","        empty_total = input_empty.sum().item()\n","        empty_accuracy = empty_correct / empty_total\n","    else:\n","        empty_accuracy = 1.0\n","\n","    # Overall accuracy: accuracy on all cells\n","    overall_accuracy = (pred_indices == target_indices).float().mean().item()\n","\n","    return {\n","        'complete': complete_correct,\n","        'empty': empty_accuracy,\n","        'overall': overall_accuracy\n","    }\n","\n","def evaluate_split(model, split_name, num_samples, criterion=None):\n","    \"\"\"Evaluate model on a specific split\"\"\"\n","    model.eval()\n","    # Use batch_size=1 to handle variable sizes\n","    # For train and test, use the specified parameters\n","    if split_name in ['train', 'test']:\n","        dataloader = dataset.get_dataloader(split_name, batch_size=1, shuffle=False,\n","                                            min_empty=min_empty, max_empty=max_empty,\n","                                            include_extreme=include_extreme)\n","    else:\n","        # For test_extreme, challenge, nikoli, no need for empty range parameters\n","        dataloader = dataset.get_dataloader(split_name, batch_size=1, shuffle=False)\n","\n","    total_loss = 0\n","    all_metrics = {'complete': [], 'empty': [], 'overall': []}\n","    samples_evaluated = 0\n","\n","    with torch.no_grad():\n","        for i, (input_data, target_data) in enumerate(dataloader):\n","            if samples_evaluated >= num_samples:\n","                break\n","\n","            # Skip non-81 cell puzzles\n","            if input_data.shape[1] != 81:\n","                continue\n","\n","            input_data = input_data.to(device)\n","            target_data = target_data.to(device)\n","\n","            # Forward pass\n","            output = model(input_data)\n","\n","            # Compute loss if criterion provided\n","            if criterion:\n","                input_empty = (input_data.sum(dim=-1) == 0).float()\n","                loss = compute_loss(output, target_data, input_empty)\n","                total_loss += loss.item() * input_data.size(0)\n","\n","            # Calculate accuracies\n","            metrics = evaluate_accuracy(output, target_data, input_data)\n","            for key in metrics:\n","                all_metrics[key].append(metrics[key])\n","\n","            samples_evaluated += input_data.size(0)\n","\n","    # Average metrics\n","    avg_metrics = {key: np.mean(values) if values else 0.0 for key, values in all_metrics.items()}\n","    avg_loss = total_loss / samples_evaluated if samples_evaluated > 0 and criterion else 0.0\n","\n","    return avg_metrics, avg_loss\n","\n","def evaluate_empty_distribution(model, split_name):\n","    \"\"\"Evaluate model accuracy by number of empty cells\"\"\"\n","    model.eval()\n","\n","    # Get subsplits from dataset\n","    if split_name == 'train':\n","        subsplits = dataset.train_subsplits\n","    elif split_name == 'test':\n","        subsplits = dataset.test_subsplits\n","    else:\n","        return None\n","\n","    empty_dist_metrics = {}\n","\n","    with torch.no_grad():\n","        for empty_count in range(min_empty, max_empty + 1):\n","            if empty_count not in subsplits:\n","                continue\n","\n","            data_list = subsplits[empty_count]\n","            if len(data_list) == 0:\n","                continue\n","\n","            complete_accs = []\n","            empty_accs = []\n","            overall_accs = []\n","\n","            # Evaluate samples for this empty count\n","            for input_data, target_data in data_list[:100]:  # Limit to 100 samples per empty count\n","                # Skip non-81 cell puzzles\n","                if input_data.shape[0] != 81:\n","                    continue\n","\n","                input_data = input_data.unsqueeze(0).to(device)\n","                target_data = target_data.unsqueeze(0).to(device)\n","\n","                # Forward pass\n","                output = model(input_data)\n","\n","                # Calculate accuracies\n","                metrics = evaluate_accuracy(output, target_data, input_data)\n","                complete_accs.append(metrics['complete'])\n","                empty_accs.append(metrics['empty'])\n","                overall_accs.append(metrics['overall'])\n","\n","            if complete_accs:\n","                empty_dist_metrics[empty_count] = {\n","                    'complete': np.mean(complete_accs),\n","                    'empty': np.mean(empty_accs),\n","                    'overall': np.mean(overall_accs),\n","                    'count': len(complete_accs)\n","                }\n","\n","    return empty_dist_metrics\n","\n","def save_checkpoint(model, optimizer, history, samples_processed):\n","    \"\"\"Save model checkpoint\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","    # Create filename with key parameters\n","    if model_type == \"StaticDEQ\":\n","        params_str = f\"Static_H{static_hidden_dimension}_I{static_iterations}_W{static_num_weight_matrices}\"\n","    elif model_type == \"HierarchicalDEQ\":\n","        params_str = f\"Hier_H{hier_hidden_dimension}_S{len(hier_iterations_per_stage.split(','))}\"\n","    else:  # HyperDEQ\n","        params_str = f\"Hyper_H{hyper_hidden_dimension}_Heads{hyper_num_heads}\"\n","\n","    params_str += f\"_bs{batch_size}_lr{learning_rate}_s{samples_processed}_{timestamp}\"\n","\n","    save_path = os.path.join(save_directory, params_str)\n","\n","    # Save complete checkpoint\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'model_config': {\n","            'model_type': model_type,\n","            'T': T, 'C': C,\n","            'hidden_activation': hidden_activation,\n","            'output_activation': output_activation,\n","            'weight_initialization': weight_initialization,\n","            'use_bias': use_bias,\n","            'use_sudoku_positional': use_sudoku_positional\n","        },\n","        'training_config': {\n","            'max_training_samples': max_training_samples,\n","            'batch_size': batch_size,\n","            'learning_rate': learning_rate,\n","            'weight_decay': weight_decay,\n","            'optimizer_type': optimizer_type,\n","            'momentum_for_sgd': momentum_for_sgd,\n","            'loss_on_empty_cells_only': loss_on_empty_cells_only,\n","            'gradient_clip_value': gradient_clip_value,\n","            'samples_processed': samples_processed,\n","            'min_empty': min_empty,\n","            'max_empty': max_empty,\n","            'include_extreme': include_extreme\n","        },\n","        'history': history\n","    }, save_path + '_checkpoint.pt')\n","\n","    print(f\"Checkpoint saved to {save_path}_checkpoint.pt\")\n","\n","def train_model():\n","    \"\"\"Main training loop\"\"\"\n","    # Create model and optimizer\n","    model = create_model()\n","    optimizer = create_optimizer(model)\n","\n","    # Training history\n","    history = {\n","        'train_loss': [], 'test_loss': [], 'test_extreme_loss': [],\n","        'challenge_loss': [], 'nikoli_loss': [],\n","        'train_complete': [], 'test_complete': [], 'test_extreme_complete': [],\n","        'challenge_complete': [], 'nikoli_complete': [],\n","        'train_empty': [], 'test_empty': [], 'test_extreme_empty': [],\n","        'challenge_empty': [], 'nikoli_empty': [],\n","        'train_overall': [], 'test_overall': [], 'test_extreme_overall': [],\n","        'challenge_overall': [], 'nikoli_overall': []\n","    }\n","\n","    # Create data loader for training\n","    train_loader = dataset.get_dataloader('train', batch_size=batch_size, shuffle=True,\n","                                          min_empty=min_empty, max_empty=max_empty,\n","                                          include_extreme=include_extreme)\n","\n","    # Training loop\n","    model.train()\n","    samples_processed = 0\n","    batch_count = 0\n","    recent_losses = []\n","    recent_metrics = {'complete': [], 'empty': [], 'overall': []}\n","\n","    print(f\"Starting training for {max_training_samples} samples...\")\n","    pbar = tqdm(total=max_training_samples,\n","            desc=\"Training\",\n","            position=0,\n","            leave=True,\n","            ncols=100)\n","\n","    while samples_processed < max_training_samples:\n","        for input_data, target_data in train_loader:\n","            if samples_processed >= max_training_samples:\n","                break\n","\n","            input_data = input_data.to(device)\n","            target_data = target_data.to(device)\n","\n","            # Forward pass\n","            output = model(input_data)\n","\n","            # Compute loss\n","            input_empty = (input_data.sum(dim=-1) == 0).float()\n","            loss = compute_loss(output, target_data, input_empty, entropy_weight=entropy_weight)\n","\n","            # Backward pass\n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            # Gradient clipping\n","            if gradient_clip_value > 0:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_value)\n","\n","            optimizer.step()\n","\n","            # Track metrics\n","            recent_losses.append(loss.item())\n","            metrics = evaluate_accuracy(output.detach(), target_data, input_data)\n","            for key in metrics:\n","                recent_metrics[key].append(metrics[key])\n","\n","            samples_processed += input_data.size(0)\n","            batch_count += 1\n","            pbar.update(input_data.size(0))\n","\n","            # Logging\n","            if samples_processed % logging_interval_samples <= batch_size:\n","                avg_loss = np.mean(recent_losses)\n","                avg_metrics = {key: np.mean(values) for key, values in recent_metrics.items()}\n","\n","                print(f\"\\nSamples: {samples_processed}/{max_training_samples}\")\n","                print(f\"Train Loss: {avg_loss:.4f}\")\n","                print(f\"Train Acc - Complete: {avg_metrics['complete']:.2%}, \"\n","                      f\"Empty: {avg_metrics['empty']:.2%}, \"\n","                      f\"Overall: {avg_metrics['overall']:.2%}\")\n","\n","                # Store training metrics\n","                history['train_loss'].append(avg_loss)\n","                for key in ['complete', 'empty', 'overall']:\n","                    history[f'train_{key}'].append(avg_metrics[key])\n","\n","                # Reset recent tracking\n","                recent_losses = []\n","                recent_metrics = {'complete': [], 'empty': [], 'overall': []}\n","\n","            # Testing\n","            if samples_processed % evaluation_interval_samples <= batch_size:\n","                print(\"\\nEvaluating...\")\n","\n","                # Evaluate on all splits\n","                test_metrics, test_loss = evaluate_split(model, 'test', test_evaluation_samples, criterion=True)\n","                test_extreme_metrics, test_extreme_loss = evaluate_split(model, 'test_extreme', 100, criterion=True)\n","                challenge_metrics, challenge_loss = evaluate_split(model, 'challenge', challenge_evaluation_samples, criterion=True)\n","                nikoli_metrics, nikoli_loss = evaluate_split(model, 'nikoli', nikoli_evaluation_samples, criterion=True)\n","\n","                # Store history\n","                history['test_loss'].append(test_loss)\n","                history['test_extreme_loss'].append(test_extreme_loss)\n","                history['challenge_loss'].append(challenge_loss)\n","                history['nikoli_loss'].append(nikoli_loss)\n","\n","                for key in ['complete', 'empty', 'overall']:\n","                    history[f'test_{key}'].append(test_metrics[key])\n","                    history[f'test_extreme_{key}'].append(test_extreme_metrics[key])\n","                    history[f'challenge_{key}'].append(challenge_metrics[key])\n","                    history[f'nikoli_{key}'].append(nikoli_metrics[key])\n","\n","                print(f\"Test - Loss: {test_loss:.4f}, Complete: {test_metrics['complete']:.2%}, \"\n","                      f\"Empty: {test_metrics['empty']:.2%}, Overall: {test_metrics['overall']:.2%}\")\n","                print(f\"Test Extreme - Loss: {test_extreme_loss:.4f}, Complete: {test_extreme_metrics['complete']:.2%}, \"\n","                      f\"Empty: {test_extreme_metrics['empty']:.2%}, Overall: {test_extreme_metrics['overall']:.2%}\")\n","                print(f\"Challenge - Loss: {challenge_loss:.4f}, Complete: {challenge_metrics['complete']:.2%}, \"\n","                      f\"Empty: {challenge_metrics['empty']:.2%}, Overall: {challenge_metrics['overall']:.2%}\")\n","                print(f\"Nikoli - Loss: {nikoli_loss:.4f}, Complete: {nikoli_metrics['complete']:.2%}, \"\n","                      f\"Empty: {nikoli_metrics['empty']:.2%}, Overall: {nikoli_metrics['overall']:.2%}\")\n","\n","                model.train()\n","\n","            # Save checkpoint\n","            if save_model and samples_processed % save_interval_samples <= batch_size:\n","                save_checkpoint(model, optimizer, history, samples_processed)\n","\n","    pbar.close()\n","    print(\"Training completed!\")\n","\n","    return model, history\n","\n","def plot_training_history(history):\n","    \"\"\"Plot training history\"\"\"\n","    if not show_plots:\n","        return\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","\n","    # Loss plot\n","    ax = axes[0, 0]\n","    if history['train_loss']:\n","        x_train = np.arange(1, len(history['train_loss']) + 1) * logging_interval_samples\n","        ax.plot(x_train, history['train_loss'], label='Train', marker='o', markersize=3)\n","    if history['test_loss']:\n","        x_test = np.arange(1, len(history['test_loss']) + 1) * evaluation_interval_samples\n","        ax.plot(x_test, history['test_loss'], label='Test', marker='o')\n","        ax.plot(x_test, history['test_extreme_loss'], label='Test Extreme', marker='d')\n","        ax.plot(x_test, history['challenge_loss'], label='Challenge', marker='s')\n","        ax.plot(x_test, history['nikoli_loss'], label='Nikoli', marker='^')\n","    ax.set_xlabel('Samples Processed')\n","    ax.set_ylabel('Loss')\n","    ax.set_title('Loss Over Training')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Complete accuracy plot\n","    ax = axes[0, 1]\n","    if history['train_complete']:\n","        x_train = np.arange(1, len(history['train_complete']) + 1) * logging_interval_samples\n","        ax.plot(x_train, history['train_complete'], label='Train', marker='o', markersize=3)\n","    if history['test_complete']:\n","        x_test = np.arange(1, len(history['test_complete']) + 1) * evaluation_interval_samples\n","        ax.plot(x_test, history['test_complete'], label='Test', marker='o')\n","        ax.plot(x_test, history['test_extreme_complete'], label='Test Extreme', marker='d')\n","        ax.plot(x_test, history['challenge_complete'], label='Challenge', marker='s')\n","        ax.plot(x_test, history['nikoli_complete'], label='Nikoli', marker='^')\n","    ax.set_xlabel('Samples Processed')\n","    ax.set_ylabel('Complete Accuracy')\n","    ax.set_title('Complete Puzzle Accuracy')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Empty cell accuracy plot\n","    ax = axes[1, 0]\n","    if history['train_empty']:\n","        x_train = np.arange(1, len(history['train_empty']) + 1) * logging_interval_samples\n","        ax.plot(x_train, history['train_empty'], label='Train', marker='o', markersize=3)\n","    if history['test_empty']:\n","        x_test = np.arange(1, len(history['test_empty']) + 1) * evaluation_interval_samples\n","        ax.plot(x_test, history['test_empty'], label='Test', marker='o')\n","        ax.plot(x_test, history['test_extreme_empty'], label='Test Extreme', marker='d')\n","        ax.plot(x_test, history['challenge_empty'], label='Challenge', marker='s')\n","        ax.plot(x_test, history['nikoli_empty'], label='Nikoli', marker='^')\n","    ax.set_xlabel('Samples Processed')\n","    ax.set_ylabel('Empty Cell Accuracy')\n","    ax.set_title('Empty Cell Accuracy')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Overall accuracy plot\n","    ax = axes[1, 1]\n","    if history['train_overall']:\n","        x_train = np.arange(1, len(history['train_overall']) + 1) * logging_interval_samples\n","        ax.plot(x_train, history['train_overall'], label='Train', marker='o', markersize=3)\n","    if history['test_overall']:\n","        x_test = np.arange(1, len(history['test_overall']) + 1) * evaluation_interval_samples\n","        ax.plot(x_test, history['test_overall'], label='Test', marker='o')\n","        ax.plot(x_test, history['test_extreme_overall'], label='Test Extreme', marker='d')\n","        ax.plot(x_test, history['challenge_overall'], label='Challenge', marker='s')\n","        ax.plot(x_test, history['nikoli_overall'], label='Nikoli', marker='^')\n","    ax.set_xlabel('Samples Processed')\n","    ax.set_ylabel('Overall Accuracy')\n","    ax.set_title('Overall Accuracy')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","\n","    if save_plots:\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        plt.savefig(os.path.join(save_directory, f'training_history_{timestamp}.png'))\n","\n","    plt.show()\n","\n","def plot_empty_distribution(model):\n","    \"\"\"Plot accuracy distribution by number of empty cells\"\"\"\n","    if not show_plots:\n","        return\n","\n","    print(\"\\nEvaluating accuracy by number of empty cells...\")\n","\n","    # Get distributions for train and test\n","    train_dist = evaluate_empty_distribution(model, 'train')\n","    test_dist = evaluate_empty_distribution(model, 'test')\n","\n","    if not train_dist and not test_dist:\n","        print(\"No distribution data available\")\n","        return\n","\n","    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n","\n","    # Prepare data\n","    empty_counts = sorted(set(list(train_dist.keys()) + list(test_dist.keys())))\n","\n","    # Complete accuracy\n","    ax = axes[0]\n","    train_complete = [train_dist.get(ec, {}).get('complete', 0) for ec in empty_counts]\n","    test_complete = [test_dist.get(ec, {}).get('complete', 0) for ec in empty_counts]\n","\n","    x = np.arange(len(empty_counts))\n","    width = 0.35\n","\n","    ax.bar(x - width/2, train_complete, width, label='Train', alpha=0.8)\n","    ax.bar(x + width/2, test_complete, width, label='Test', alpha=0.8)\n","    ax.set_xlabel('Number of Empty Cells')\n","    ax.set_ylabel('Complete Accuracy')\n","    ax.set_title('Complete Puzzle Accuracy by Empty Cells')\n","    ax.set_xticks(x[::5])\n","    ax.set_xticklabels(empty_counts[::5])\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Empty cell accuracy\n","    ax = axes[1]\n","    train_empty = [train_dist.get(ec, {}).get('empty', 0) for ec in empty_counts]\n","    test_empty = [test_dist.get(ec, {}).get('empty', 0) for ec in empty_counts]\n","\n","    ax.bar(x - width/2, train_empty, width, label='Train', alpha=0.8)\n","    ax.bar(x + width/2, test_empty, width, label='Test', alpha=0.8)\n","    ax.set_xlabel('Number of Empty Cells')\n","    ax.set_ylabel('Empty Cell Accuracy')\n","    ax.set_title('Empty Cell Accuracy by Empty Cells')\n","    ax.set_xticks(x[::5])\n","    ax.set_xticklabels(empty_counts[::5])\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    # Overall accuracy\n","    ax = axes[2]\n","    train_overall = [train_dist.get(ec, {}).get('overall', 0) for ec in empty_counts]\n","    test_overall = [test_dist.get(ec, {}).get('overall', 0) for ec in empty_counts]\n","\n","    ax.bar(x - width/2, train_overall, width, label='Train', alpha=0.8)\n","    ax.bar(x + width/2, test_overall, width, label='Test', alpha=0.8)\n","    ax.set_xlabel('Number of Empty Cells')\n","    ax.set_ylabel('Overall Accuracy')\n","    ax.set_title('Overall Accuracy by Empty Cells')\n","    ax.set_xticks(x[::5])\n","    ax.set_xticklabels(empty_counts[::5])\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","\n","    if save_plots:\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        plt.savefig(os.path.join(save_directory, f'empty_distribution_{timestamp}.png'))\n","\n","    plt.show()\n","\n","def display_predictions(model, num_samples=None):\n","    \"\"\"Display sample predictions from each split\"\"\"\n","    if not show_plots:\n","        return\n","\n","    if num_samples is None:\n","        num_samples = num_prediction_samples_to_show\n","\n","    model.eval()\n","\n","    splits = ['train', 'test', 'test_extreme', 'challenge', 'nikoli']\n","\n","    fig, axes = plt.subplots(len(splits), num_samples * 3, figsize=(3 * num_samples * 3, 3 * len(splits)))\n","\n","    # Handle case where axes might not be 2D\n","    if len(splits) == 1:\n","        axes = axes.reshape(1, -1)\n","    if num_samples == 1:\n","        axes = axes.reshape(-1, 3)\n","\n","    for split_idx, split_name in enumerate(splits):\n","        # Use batch_size=1 to handle variable sizes\n","        # For train and test, use the specified parameters\n","        if split_name in ['train', 'test']:\n","            dataloader = dataset.get_dataloader(split_name, batch_size=1, shuffle=True,\n","                                               min_empty=min_empty, max_empty=max_empty,\n","                                               include_extreme=include_extreme)\n","        else:\n","            # For test_extreme, challenge, nikoli, no need for empty range parameters\n","            dataloader = dataset.get_dataloader(split_name, batch_size=1, shuffle=True)\n","\n","        samples_shown = 0\n","        with torch.no_grad():\n","            for input_data, target_data in dataloader:\n","                if samples_shown >= num_samples:\n","                    break\n","\n","                # Skip non-81 cell puzzles\n","                if input_data.shape[1] != 81:\n","                    continue\n","\n","                input_data = input_data.to(device)\n","                output = model(input_data)\n","\n","                # Input\n","                ax = axes[split_idx, samples_shown * 3]\n","                ax.set_title(f'{split_name} - Input {samples_shown+1}')\n","                ax.text(0.5, 0.5, sample_to_grid(input_data[0].cpu(), 'tokenized'),\n","                       ha='center', va='center', fontfamily='monospace', fontsize=8)\n","                ax.axis('off')\n","\n","                # Prediction\n","                ax = axes[split_idx, samples_shown * 3 + 1]\n","                ax.set_title(f'{split_name} - Prediction {samples_shown+1}')\n","                ax.text(0.5, 0.5, sample_to_grid(output[0].cpu(), 'tokenized'),\n","                       ha='center', va='center', fontfamily='monospace', fontsize=8)\n","                ax.axis('off')\n","\n","                # Target\n","                ax = axes[split_idx, samples_shown * 3 + 2]\n","                ax.set_title(f'{split_name} - Target {samples_shown+1}')\n","                ax.text(0.5, 0.5, sample_to_grid(target_data[0].cpu(), 'tokenized'),\n","                       ha='center', va='center', fontfamily='monospace', fontsize=8)\n","                ax.axis('off')\n","\n","                samples_shown += 1\n","\n","    plt.tight_layout()\n","\n","    if save_plots:\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        plt.savefig(os.path.join(save_directory, f'predictions_{timestamp}.png'))\n","\n","    plt.show()"]}]}