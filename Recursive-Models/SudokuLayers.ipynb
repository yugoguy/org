{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4MJ1pyqsIqF/0l+TrKC7S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t_-e45euS-wz"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class SudokuPositionalEncoding(nn.Module):\n","    \"\"\"\n","    数独専用のPositional Encoding付きInput Projection\n","    行、列、3x3ブロックの位置情報を学習可能なembeddingとして追加\n","    \"\"\"\n","\n","    def __init__(self, C, D, bias=False):\n","        \"\"\"\n","        Args:\n","            C: 入力次元（数独の場合は9）\n","            D: 出力次元（隠れ層の次元）\n","            bias: Linear層でbiasを使うかどうか\n","        \"\"\"\n","        super().__init__()\n","\n","        # 元のLinear投影層\n","        self.linear = nn.Linear(C, D, bias=bias)\n","\n","        # 位置埋め込み（行、列、ブロックそれぞれ9個）\n","        self.row_embedding = nn.Parameter(torch.randn(9, D) * 0.02)\n","        self.col_embedding = nn.Parameter(torch.randn(9, D) * 0.02)\n","        self.block_embedding = nn.Parameter(torch.randn(9, D) * 0.02)\n","\n","        # positional encodingのスケール係数（学習可能）\n","        self.pos_scale = nn.Parameter(torch.tensor(0.1))\n","\n","        # パラメータ情報を保持（互換性のため）\n","        self.in_features = C\n","        self.out_features = D\n","        self.weight = self.linear.weight  # 元のlinearの重みへの参照\n","        if bias:\n","            self.bias = self.linear.bias\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Args:\n","            X: 入力テンソル (B, T=81, C=9)\n","\n","        Returns:\n","            位置エンコーディング付きの出力 (B, T=81, D)\n","        \"\"\"\n","        B, T, C = X.shape\n","        device = X.device\n","\n","        # Linear投影\n","        X_proj = self.linear(X)  # (B, T, D)\n","\n","        # 各セルの位置エンコーディングを構築\n","        pos_encoding = []\n","        for idx in range(81):\n","            row = idx // 9\n","            col = idx % 9\n","            block = (row // 3) * 3 + (col // 3)\n","\n","            # 3つの位置埋め込みを加算\n","            pos = self.row_embedding[row] + self.col_embedding[col] + self.block_embedding[block]\n","            pos_encoding.append(pos)\n","\n","        # テンソルにまとめてバッチ次元を追加\n","        pos_encoding = torch.stack(pos_encoding).unsqueeze(0)  # (1, 81, D)\n","        pos_encoding = pos_encoding.expand(B, -1, -1).to(device)\n","\n","        # 投影結果と位置エンコーディングを加算\n","        output = X_proj + self.pos_scale * pos_encoding\n","\n","        return output\n","\n","\n","def add_sudoku_positional_encoding(model):\n","    \"\"\"\n","    既存のDEQモデルのinput_projをSudoku用positional encoding付きに置き換える\n","\n","    Args:\n","        model: StaticDEQ, HierarchicalDEQ, またはHyperDEQのインスタンス\n","\n","    Returns:\n","        input_projが置き換えられた同じモデルインスタンス\n","    \"\"\"\n","\n","    # 元のinput_projのパラメータを取得\n","    old_input_proj = model.input_proj\n","    C = old_input_proj.in_features\n","    D = old_input_proj.out_features\n","    bias = old_input_proj.bias is not None\n","\n","    # 新しいSudoku用投影層を作成\n","    new_input_proj = SudokuPositionalEncoding(C, D, bias=bias)\n","\n","    # 元のLinear層の重みをコピー（学習済みモデルの場合に重要）\n","    with torch.no_grad():\n","        new_input_proj.linear.weight.copy_(old_input_proj.weight)\n","        if bias:\n","            new_input_proj.linear.bias.copy_(old_input_proj.bias)\n","\n","    # モデルのinput_projを置き換え\n","    model.input_proj = new_input_proj\n","\n","    # デバイスを合わせる\n","    if next(model.parameters()).is_cuda:\n","        model.input_proj = model.input_proj.cuda()\n","\n","    return model"]}]}