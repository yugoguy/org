{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvgdYNVLODvFozWcjpIThw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","FractalAutoencoder Training Script for Google Colab\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from typing import Dict, List, Tuple\n","import time\n","\n","# ===== Parse Parameters =====\n","def parse_list_param(param_str: str) -> List[int]:\n","    \"\"\"文字列パラメータをリストに変換\"\"\"\n","    return [int(x.strip()) for x in param_str.split(',')]\n","\n","# ===== Training Functions =====\n","def train_epoch(model, train_loader, optimizer, device, epoch, log_interval=10):\n","    \"\"\"1エポックの学習\"\"\"\n","    model.train()\n","    losses = []\n","\n","    pbar = tqdm(train_loader, desc=f'Epoch {epoch} [Train]')\n","    for batch_idx, (masked_images, original_images, masks, labels) in enumerate(pbar):\n","        # デバイスに転送\n","        masked_images = masked_images.to(device)\n","        original_images = original_images.to(device)\n","\n","        # 順伝播\n","        optimizer.zero_grad()\n","        outputs = model(masked_images)\n","\n","        # 損失計算（シンプルなMSE）\n","        loss = nn.functional.mse_loss(outputs, original_images)\n","\n","        # 逆伝播\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 記録\n","        losses.append(loss.item())\n","\n","        # 直近の平均損失を表示\n","        if batch_idx % log_interval == 0:\n","            recent_loss = np.mean(losses[-log_interval:]) if len(losses) >= log_interval else np.mean(losses)\n","            pbar.set_postfix({'loss': f'{recent_loss:.4f}'})\n","\n","    return losses\n","\n","def evaluate(model, test_loader, device, num_samples=None):\n","    \"\"\"評価\"\"\"\n","    model.eval()\n","    losses = []\n","\n","    with torch.no_grad():\n","        for idx, (masked_images, original_images, masks, labels) in enumerate(test_loader):\n","            if num_samples and idx * test_loader.batch_size >= num_samples:\n","                break\n","\n","            masked_images = masked_images.to(device)\n","            original_images = original_images.to(device)\n","\n","            outputs = model(masked_images)\n","            loss = nn.functional.mse_loss(outputs, original_images)\n","            losses.append(loss.item())\n","\n","    return np.mean(losses)\n","\n","def visualize_results(model, dataloader, device, num_samples=4, epoch=0):\n","    \"\"\"結果の可視化\"\"\"\n","    model.eval()\n","\n","    # データ取得\n","    masked_images, original_images, masks, labels = next(iter(dataloader))\n","    num_samples = min(num_samples, len(masked_images))\n","\n","    # 推論\n","    with torch.no_grad():\n","        masked_images_device = masked_images[:num_samples].to(device)\n","        reconstructed = model(masked_images_device).cpu()\n","\n","    # データセット情報\n","    dataset = dataloader.dataset\n","    is_grayscale = dataset.effective_channels == 1\n","    image_shape = dataset.effective_shape\n","\n","    # Reshape if flattened\n","    if dataset.flatten:\n","        if is_grayscale:\n","            h, w = image_shape\n","            masked_vis = masked_images[:num_samples].reshape(num_samples, h, w)\n","            original_vis = original_images[:num_samples].reshape(num_samples, h, w)\n","            reconstructed_vis = reconstructed.reshape(num_samples, h, w)\n","            masks_vis = masks[:num_samples].reshape(num_samples, h, w)\n","        else:\n","            h, w, c = image_shape\n","            masked_vis = masked_images[:num_samples].reshape(num_samples, h, w, c)\n","            original_vis = original_images[:num_samples].reshape(num_samples, h, w, c)\n","            reconstructed_vis = reconstructed.reshape(num_samples, h, w, c)\n","            # ピクセル単位マスクなので、最初のチャンネルだけ取る（全チャンネル同じ）\n","            masks_vis = masks[:num_samples].reshape(num_samples, h, w, c)[:, :, :, 0]\n","\n","    # Visualization\n","    fig, axes = plt.subplots(num_samples, 3, figsize=(9, 3*num_samples))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    for i in range(num_samples):\n","        # Masked\n","        ax = axes[i, 0]\n","        if is_grayscale:\n","            ax.imshow(masked_vis[i], cmap='gray', vmin=0, vmax=1)\n","        else:\n","            ax.imshow(masked_vis[i], vmin=0, vmax=1)\n","        ax.set_title(f'Masked ({(1-masks_vis[i].mean()):.1%})')\n","        ax.axis('off')\n","\n","        # Reconstructed\n","        ax = axes[i, 1]\n","        if is_grayscale:\n","            ax.imshow(reconstructed_vis[i], cmap='gray', vmin=0, vmax=1)\n","        else:\n","            ax.imshow(np.clip(reconstructed_vis[i], 0, 1))\n","        # シンプルなMSE計算\n","        mse = ((original_vis[i] - reconstructed_vis[i])**2).mean()\n","        ax.set_title(f'Predicted (MSE: {mse:.4f})')\n","        ax.axis('off')\n","\n","        # Original\n","        ax = axes[i, 2]\n","        if is_grayscale:\n","            ax.imshow(original_vis[i], cmap='gray', vmin=0, vmax=1)\n","        else:\n","            ax.imshow(original_vis[i], vmin=0, vmax=1)\n","        ax.set_title(f'Original (Label: {labels[i]})')\n","        ax.axis('off')\n","\n","    plt.suptitle(f'Epoch {epoch} Results', fontsize=14)\n","    plt.tight_layout()\n","    plt.show()\n","\n","    return fig\n","\n","# ===== Main Training Loop =====\n","def main():\n","    \"\"\"メイン学習ループ\"\"\"\n","\n","    # データローダー作成\n","    print(\"Loading dataset...\")\n","    train_loader, test_loader, input_dim = create_dataloader(\n","        dataset_name=dataset_name,\n","        batch_size=batch_size,\n","        mask_ratio=mask_ratio,\n","        flatten=True,\n","        normalize=True,\n","        grayscale=grayscale,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","    print(f\"Dataset: {dataset_name}, Input dim: {input_dim}\")\n","    print(f\"Train samples: {len(train_loader.dataset)}, Test samples: {len(test_loader.dataset)}\")\n","\n","    # モデル設定\n","    config = FractalConfig(\n","        max_depth=max_depth,\n","        input_dim=input_dim,\n","        output_dim=input_dim,  # 再構成タスクなので同じ次元\n","        num_iterations=num_iterations,\n","        gate_momentum=gate_momentum,\n","        use_ffn=use_ffn,\n","        attention_heads=attention_heads,\n","        head_dims=head_dims,\n","        proto_dims=proto_dims,\n","        proto_nums=proto_nums\n","    )\n","\n","    # モデル作成\n","    print(\"\\nCreating model...\")\n","    model = FractalAutoencoder(config).to(device)\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"Total parameters: {total_params:,}\")\n","\n","    # オプティマイザ\n","    if optimizer_type == \"Adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    elif optimizer_type == \"AdamW\":\n","        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    else:  # SGD\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n","\n","    # スケジューラ\n","    scheduler = None\n","    if scheduler_type == \"StepLR\":\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=scheduler_factor)\n","    elif scheduler_type == \"CosineAnnealingLR\":\n","        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n","    elif scheduler_type == \"ReduceLROnPlateau\":\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=scheduler_factor, patience=scheduler_patience)\n","\n","    # 学習履歴\n","    history = {'train_loss': [], 'test_loss': [], 'epoch_times': []}\n","    best_test_loss = float('inf')\n","\n","    # 学習ループ\n","    print(\"\\nStarting training...\")\n","    for epoch in range(1, epochs + 1):\n","        start_time = time.time()\n","\n","        # Train\n","        train_losses = train_epoch(model, train_loader, optimizer, device, epoch, log_interval)\n","        train_loss = np.mean(train_losses[-log_interval:])  # 直近の平均\n","\n","        # Test\n","        test_loss = evaluate(model, test_loader, device, num_samples=test_samples)\n","\n","        # 記録\n","        epoch_time = time.time() - start_time\n","        history['train_loss'].append(train_loss)\n","        history['test_loss'].append(test_loss)\n","        history['epoch_times'].append(epoch_time)\n","\n","        # 表示\n","        print(f\"\\nEpoch {epoch}/{epochs}\")\n","        print(f\"  Train Loss (recent): {train_loss:.6f}\")\n","        print(f\"  Test Loss: {test_loss:.6f}\")\n","        print(f\"  Time: {epoch_time:.1f}s\")\n","\n","        # 可視化\n","        print(\"\\nVisualizing results...\")\n","        visualize_results(model, test_loader, device, num_samples=vis_samples, epoch=epoch)\n","\n","        # ベストモデル保存\n","        if save_checkpoint and test_loss < best_test_loss:\n","            best_test_loss = test_loss\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'test_loss': test_loss,\n","                'config': config,\n","            }, checkpoint_path)\n","            print(f\"  Saved best model (test_loss: {test_loss:.6f})\")\n","\n","        # スケジューラ更新\n","        if scheduler:\n","            if scheduler_type == \"ReduceLROnPlateau\":\n","                scheduler.step(test_loss)\n","            else:\n","                scheduler.step()\n","\n","        print(\"-\" * 50)\n","\n","    # 最終結果\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"Training Complete!\")\n","    print(f\"Best Test Loss: {best_test_loss:.6f}\")\n","    print(f\"Total Time: {sum(history['epoch_times']):.1f}s\")\n","\n","    # Loss曲線をプロット\n","    plt.figure(figsize=(10, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history['train_loss'], label='Train Loss (recent)')\n","    plt.plot(history['test_loss'], label='Test Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history['epoch_times'])\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Time (s)')\n","    plt.title('Epoch Time')\n","    plt.grid(True)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    return model, history\n"],"metadata":{"id":"JI2N9ONKdZsI"},"execution_count":null,"outputs":[]}]}